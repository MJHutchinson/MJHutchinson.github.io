[{"authors":["admin"],"categories":null,"content":"Hi I\u0026rsquo;m Michael! I\u0026rsquo;m interested in machine learning, particularly the Bayesian flavour.\nRecently I have been working on Equivariance in Deep Learning, and various COIVD-19 statistical modelling efforts.\nPreviously I\u0026rsquo;ve worked on Architecture Search of Bayesian Neural Networks, and Differential Privacy for Federated and Continual Bayesian Learning.\nBroadly I\u0026rsquo;m interested in statistically principled machine learning. I\u0026rsquo;m working on pushing the theoretical boundaries of this, and help make it useful in the real world!\nMy interests aren\u0026rsquo;t completely settled however, and I\u0026rsquo;m always keen to explore new areas. Reinforcement Learning is the next on my todo list.\nI recently started a PhD course at the University of Oxford through the StatML course, supervised by Yee Whye Teh and Max Welling. Before that I completed a Masters of Engineering at the University of Cambridge, supervised by Dr Rich E. Turner.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://mjhutchinson.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hi I\u0026rsquo;m Michael! I\u0026rsquo;m interested in machine learning, particularly the Bayesian flavour.\nRecently I have been working on Equivariance in Deep Learning, and various COIVD-19 statistical modelling efforts.\nPreviously I\u0026rsquo;ve worked on Architecture Search of Bayesian Neural Networks, and Differential Privacy for Federated and Continual Bayesian Learning.\nBroadly I\u0026rsquo;m interested in statistically principled machine learning. I\u0026rsquo;m working on pushing the theoretical boundaries of this, and help make it useful in the real world!","tags":null,"title":"Michael Hutchinson","type":"authors"},{"authors":["**Michael Hutchinson***","Charline Le Lan*","Sheheryar Zaidi*","Emilien Dupont","Yee Whye Teh","Hyunjik Kim"],"categories":null,"content":"","date":1608422400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608422400,"objectID":"b9952e84b049214ee82fe948103ace18","permalink":"https://mjhutchinson.github.io/publication/hutchinson-2020-lietransformer/","publishdate":"2020-12-22T13:42:27.527123Z","relpermalink":"/publication/hutchinson-2020-lietransformer/","section":"publication","summary":"Group equivariant neural networks are used as building blocks of group invariant neural networks, which have been shown to improve generalisation performance and data efficiency through principled parameter sharing. Such works have mostly focused on group equivariant convolutions, building on the result that group equivariant linear maps are necessarily convolutions. In this work, we extend the scope of the literature to non-linear neural network modules, namely self-attention, that is emerging as a prominent building block of deep learning models. We propose the LieTransformer, an architecture composed of LieSelfAttention layers that are equivariant to arbitrary Lie groups and their discrete subgroups. We demonstrate the generality of our approach by showing experimental results that are competitive to baseline methods on a wide range of tasks: shape counting on point clouds, molecular property regression and modelling particle trajectories under Hamiltonian dynamics.","tags":null,"title":"LieTransformer: Equivariant self-attention for Lie Groups","type":"publication"},{"authors":["Peter Holderrieth*","**Michael Hutchinson***","Yee Whye Teh"],"categories":null,"content":"","date":1606262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606262400,"objectID":"075b2df859acc3c86b38e65da2647d11","permalink":"https://mjhutchinson.github.io/publication/holderrieth-2020-equivariant/","publishdate":"2020-12-22T13:42:27.526915Z","relpermalink":"/publication/holderrieth-2020-equivariant/","section":"publication","summary":"","tags":null,"title":"Equivariant Learning of Stochastic Fields: Gaussian Processes and Steerable Conditional Neural Processes ","type":"publication"},{"authors":["Mélodie Monod","Alexandra Blenkinsop","Xiaoyue Xi","Daniel Hebert","Sivan Bershan","Valerie C Bradley","Yu Chen","Helen Coupland","Sarah Filippi","Jonathan Ish-Horowicz","Martin McManus","Thomas A Mellan","Axel Gandy","**Michael Hutchinson**","H Juliette T Unwin","Michaela A. C. Vollmer","Sebastian Weber","Harrison Zhu","Anne Bezancon","Simon Tietze","Neil M Ferguson","Swapnil Mishra","Seth Flaxman","Samir Bhatt","Oliver Ratmann"," "],"categories":null,"content":"","date":1600387200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600387200,"objectID":"d8a57ffdf7d63c27ea91da12b1fd5ba4","permalink":"https://mjhutchinson.github.io/publication/monod-2020-09-18-20197376/","publishdate":"2020-12-22T13:42:27.525966Z","relpermalink":"/publication/monod-2020-09-18-20197376/","section":"publication","summary":"Following initial declines, in mid 2020, a resurgence in transmission of novel coronavirus disease (COVID-19) has occurred in the United States and parts of Europe. Despite the wide implementation of non-pharmaceutical interventions, it is still not known how they are impacted by changing contact patterns, age and other demographics. As COVID-19 disease control becomes more localised, understanding the age demographics driving transmission and how these impacts the loosening of interventions such as school reopening is crucial. Considering dynamics for the United States, we analyse aggregated, age-specific mobility trends from more than 10 million individuals and link these mechanistically to age-specific COVID-19 mortality data. In contrast to previous approaches, we link mobility to mortality via age-specific contact patterns and use this rich relationship to reconstruct accurate transmission dynamics. Contrary to anecdotal evidence, we find little support for age-shifts in contact and transmission dynamics over time. We estimate that, until August, 63.4% [60.9%-65.5%] of SARS-CoV-2 infections in the United States originated from adults aged 20-49, while 1.2% [0.8%-1.8%] originated from children aged 0- 9. In areas with continued, community-wide transmission, our transmission model predicts that re-opening kindergartens and elementary schools could facilitate spread and lead to additional COVID-19 attributable deaths over a 90-day period. These findings indicate that targeting interventions to adults aged 20-49 are an important consideration in halting resurgent epidemics and preventing COVID-19-attributable deaths when kindergartens and elementary schools reopen.Competing Interest StatementSB acknowledges the National Institute for Health Research (NIHR) BRC Imperial College NHS Trust Infection and COVID themes, the Academy of Medical Sciences Springboard award and the Bill and Melinda Gates Foundation. OR reports grants from the Bill \u0026amp; Melinda Gates Foundation during the conduct of the study. Funding StatementThis study was supported by the Imperial College COVID-19 Response Fund, the Imperial College Research Computing Service DOI:10.14469/hpc/2232, the Bill \u0026amp; Melinda Gates Foundation, and the EPSRC through the EPSRC Centre for Doctoral Training in Modern Statistics and Statistical Machine Learning at Imperial and Oxford, the UK Medical Research Council under a concordat with the UK Department for International Development, the NIHR Health Protection Research Unit in Modelling Methodology and Community Jameel. We would like to thank Microsoft and Amazon for providing cloud computing services.Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:NoneAll necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).Yes I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesThe COVID-19 mortality data used in this study are available on GitHub, https://github.com/ImperialCollegeLondon/US-covid19-agespecific-mortality-data, under the Creative Commons Attribution 4.0 International Public License. Code and further data are available on Github, https://github.com/ImperialCollegeLondon/covid19model, under the MIT License. https://github.com/ImperialCollegeLondon/US-covid19-agespecific-mortality-datahttps://github.com/ImperialCollegeLondon/covid19model","tags":null,"title":"Age groups that sustain resurging COVID-19 epidemics in the United States","type":"publication"},{"authors":["Michael Hutchinson"],"categories":[],"content":" Poster presentation   Slides for this presentation\nPapers mentioned in this talk  Steerable CNNs. Cohen, T. S., \u0026amp; Welling, M. (2016). arXiv Spherical CNNs. Cohen, T. S., Geiger, M., Köhler, J., \u0026amp; Welling, M. (2018). arXiv General $E(2)$-Equivariant Steerable CNNs. Weiler, M., \u0026amp; Cesa, G. (2019). arXiv A General Theory of Equivariant CNNs on Homogeneous Spaces. Cohen, T., Geiger, M., \u0026amp; Weiler, M. (2018). arXiv Gauge Equivariant Convolutional Networks and the Icosahedral CNN. Cohen, T. S., Weiler, M., Kicanaoglu, B., \u0026amp; Welling, M. (2019). arXiv Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data. Finzi, M., Stanton, S., Izmailov, P., \u0026amp; Wilson, A. G. (2020). arXiv Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds. Thomas, N., Smidt, T., Kearnes, S., Yang, L., Li, L., Kohlhoff, K., \u0026amp; Riley, P. (2018). arXiv SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks. Fuchs, F. B., Worrall, D. E., Fischer, V., \u0026amp; Welling, M. (2020). arXiv Attentive Group Equivariant Convolutional Networks. Romero, D. W., Bekkers, E. J., Tomczak, J. M., \u0026amp; Hoogendoorn, M. (2020). arXiv  ","date":1593043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593043200,"objectID":"657217e645586c5100586ebc56abbebc","permalink":"https://mjhutchinson.github.io/post/2020-06-25-mlss/","publishdate":"2020-06-25T00:00:00Z","relpermalink":"/post/2020-06-25-mlss/","section":"post","summary":"A collection of things related to me for, and things from, the 2020 Virtual MLSS","tags":[],"title":"Machine Learning Summer School 2020","type":"post"},{"authors":["Bobby He*","Sheheryar Zaidi*","Bryn Elesedy*","**Michael Hutchinson***","Andrei Paleyes","Guy Harling","Anne Johnson","Yee Whye Teh"],"categories":null,"content":"","date":1590537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590537600,"objectID":"973d5cf97c409ce64e6e72b4da906601","permalink":"https://mjhutchinson.github.io/publication/he-2020-technical/","publishdate":"2020-05-27T12:57:16.196363Z","relpermalink":"/publication/he-2020-technical/","section":"publication","summary":"We use an individual-level transmission and contact simulation model to explore the effectiveness and resource requirements of various test-trace-isolate (TTI) strategies for reducing the spread of SARS-CoV-2 in the UK, in the context of di↵erent scenarios with varying levels of stringency of non-pharmaceutical interventions (NPIs) over the summer period.","tags":null,"title":"Technical Document 3: Effectiveness and Resource Requirements of Test, Trace and Isolate Strategies","type":"publication"},{"authors":["H Juliette T Unwin","Swapnil Mishra","Valerie C Bradley","Axel Gandy","Michaela A C Vollmer","Thomas Mellan","Helen Coupland","Kylie Ainslie","Charlie Whittaker","Jonathan Ish Horowicz","Sarah Filippi","Xiaoyue Xi","Melodie Monod","Oliver Ratmann","**Michael Hutchinson**","others_(truncated for brevity)_"],"categories":null,"content":"","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590019200,"objectID":"6154ba41da20aeaedcc9611eeb16dd88","permalink":"https://mjhutchinson.github.io/publication/unwin-2020/","publishdate":"2020-05-21T17:23:59.11936Z","relpermalink":"/publication/unwin-2020/","section":"publication","summary":"As of 20 May 2020, the US Centers for Disease Control and Prevention reported 91,664 confirmed or probable COVID19-related deaths, more than twice the number of deaths reported in the next most severely impacted country. In order to control the spread of the epidemic and prevent health care systems from being overwhelmed, US states have implemented a suite of non-pharmaceutical interventions (NPIs), including “stay-at-home” orders, bans on gatherings, and business and school closures. We model the epidemics in the US at the state-level, using publicly available death data within a Bayesian hierarchical semi-mechanistic framework. For each state, we estimate the time-varying reproduction number (the average number of secondary infections caused by an infected person), the number of individuals that have been infected and the number of individuals that are currently infectious. We use changes in mobility as a proxy for the impact that NPIs and other behaviour changes have on the rate of transmission of SARS-CoV-2. We project the impact of future increases in mobility, assuming that the relationship between mobility and disease transmission remains constant. We do not address the potential effect of additional behavioural changes or interventions, such as increased mask-wearing or testing and tracing strategies. Nationally, our estimates show that the percentage of individuals that have been infected is 4.1% [3.7%-4.5%], with wide variation between states. For all states, even for the worst affected states, we estimate that less than a quarter of the population has been infected; in New York, for example, we estimate that 16.6% [12.8%-21.6%] of individuals have been infected to date. Our attack rates for New York are in line with those from recent serological studies [1] broadly supporting our modelling choices. There is variation in the initial reproduction number, which is likely due to a range of factors; we find a strong association between the initial reproduction number with both population density (measured at the state level) and the chronological date when 10 cumulative deaths occurred (a crude estimate of the date of locally sustained transmission). Our estimates suggest that the epidemic is not under control in much of the US: as of 17 May 2020, the reproduction number is above the critical threshold (1.0) in 24 [95% CI: 20-30] states. Higher reproduction numbers are geographically clustered in the South and Midwest, where epidemics are still developing, while we estimate lower reproduction numbers in states that have already suffered high COVID-19 mortality (such as the Northeast). These estimates suggest that caution must be taken in loosening current restrictions if effective additional measures are not put in place. We predict that increased mobility following relaxation of social distancing will lead to resurgence of transmission, keeping all else constant. We predict that deaths over the next two-month period could exceed current cumulative deaths by greater than two-fold, if the relationship between mobility and transmission remains unchanged. Our results suggest that factors modulating transmission such as rapid testing, contact tracing and behavioural precautions are crucial to offset the rise of transmission associated with loosening of social distancing. Overall, we show that while all US states have substantially reduced their reproduction numbers, we find no evidence that any state is approaching herd immunity or that its epidemic is close to over.","tags":null,"title":"Report 23: State-level tracking of COVID-19 in the United States","type":"publication"},{"authors":["Thomas A Mellan","Henrique H Hoeltgebaum","Swapnil Mishra","Charlie Whittaker","Ricardo P  Schnekenberg","Axel Gandy","H Juliette T Unwin","Michaela A C Vollmer","Helen Coupland","Iwona Hawryluk","Nuno Rodrigues Faria","Juan Vesga","Harrison Zhu","**Michael Hutchinson**","others_(truncated for brevity)_"],"categories":null,"content":"","date":1588896000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588896000,"objectID":"51cf00c3bd78017186e4e84b097a56ed","permalink":"https://mjhutchinson.github.io/publication/mellan-2020-report/","publishdate":"2020-05-08T17:23:59.119037Z","relpermalink":"/publication/mellan-2020-report/","section":"publication","summary":"Brazil is an epicentre for COVID-19 in Latin America. In this report we describe the Brazilian epidemic using three epidemiological measures: the number of infections, the number of deaths and the reproduction number. Our modelling framework requires sufficient death data to estimate trends, and we therefore limit our analysis to 16 states that have experienced a total of more than fifty deaths. The distribution of deaths among states is highly heterogeneous, with 5 states—São Paulo, Rio de Janeiro, Ceará, Pernambuco and Amazonas—accounting for 81% of deaths reported to date. In these states, we estimate that the percentage of people that have been infected with SARS-CoV-2 ranges from 3.3% (95% CI: 2.8%-3.7%) in São Paulo to 10.6% (95% CI: 8.8%-12.1%) in Amazonas. The reproduction number (a measure of transmission intensity) at the start of the epidemic meant that an infected individual would infect three or four others on average. Following non-pharmaceutical interventions such as school closures and decreases in population mobility, we show that the reproduction number has dropped substantially in each state. However, for all 16 states we study, we estimate with high confidence that the reproduction number remains above 1. A reproduction number above 1 means that the epidemic is not yet controlled and will continue to grow. These trends are in stark contrast to other major COVID-19 epidemics in Europe and Asia where enforced lockdowns have successfully driven the reproduction number below 1. While the Brazilian epidemic is still relatively nascent on a national scale, our results suggest that further action is needed to limit spread and prevent health system overload.","tags":null,"title":"Report 21: Estimating COVID-19 cases and reproduction number in Brazil","type":"publication"},{"authors":["M Vollmer","S Mishra","H Unwin","A Gandy","T Melan","V Bradley","H Zhu","H Coupland","I Hawryluk","**Michael Hutchinson**","others_(truncated for brevity)_"],"categories":null,"content":"","date":1588550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588550400,"objectID":"9e2e067f7497e07a57184bd6995db73c","permalink":"https://mjhutchinson.github.io/publication/vollmer-2020-report/","publishdate":"2020-05-04T17:07:01.05408Z","relpermalink":"/publication/vollmer-2020-report/","section":"publication","summary":"Italy was the first European country to experience sustained local transmission of COVID-19. As of 1st May 2020, the Italian health authorities reported 28,238 deaths nationally. To control the epidemic, the Italian government implemented a suite of non-pharmaceutical interventions (NPIs), including school and university closures, social distancing and full lockdown involving banning of public gatherings and non essential movement. In this report, we model the effect of NPIs on transmission using data on average mobility. We estimate that the average reproduction number (a measure of transmission intensity) is currently below one for all Italian regions, and significantly so for the majority of the regions. Despite the large number of deaths, the proportion of population that has been infected by SARS-CoV-2 (the attack rate) is far from the herd immunity threshold in all Italian regions, with the highest attack rate observed in Lombardy (13.18% [10.66%-16.70%]). Italy is set to relax the currently implemented NPIs from 4th May 2020. Given the control achieved by NPIs, we consider three scenarios for the next 8 weeks: a scenario in which mobility remains the same as during the lockdown, a scenario in which mobility returns to pre-lockdown levels by 20%, and a scenario in which mobility returns to pre-lockdown levels by 40%. The scenarios explored assume that mobility is scaled evenly across all dimensions, that behaviour stays the same as before NPIs were implemented, that no pharmaceutical interventions are introduced, and it does not include transmission reduction from contact tracing, testing and the isolation of confirmed or suspected cases. Some of these factors, such as contact tracing, are likely to be introduced and will contribute to reductions in transmission; therefore our estimates should be viewed as pessimistic projections. We find that, in the absence of additional interventions, even a 20% return to pre-lockdown mobility could lead to a resurgence in the number of deaths far greater than experienced in the current wave in several regions. Future increases in the number of deaths will lag behind the increase in transmission intensity and so a second wave will not be immediately apparent from just monitoring of the daily number of deaths. Our results suggest that SARS-CoV-2 transmission as well as mobility should be closely monitored in the next weeks and months. To compensate for the increase in mobility that will occur due to the relaxation of the currently implemented NPIs, adherence to the recommended social distancing measures alongside enhanced community surveillance including swab testing, contact tracing and the early isolation of infections are of paramount importance to reduce the risk of resurgence in transmission. ","tags":null,"title":"Report 20: A sub-national analysis of the rate of transmission of Covid-19 in Italy","type":"publication"},{"authors":null,"categories":null,"content":"Today marks my first day at the Unversity of Oxford, starting a PhD in Statisitcal Machine Learning.\nI\u0026rsquo;m joining the StatML course run in the statistics department. The first year consists of two parts: A mix of taught courses covering a range of topics from classical statistical techniques, all the way through to modern deep learning, and a series of small reaserch projects. The aim of the course is to give students with a range of interests some extra time and skills to settle on a good PhD topic. The three years after the first function as a normal PhD program, but with some additional cohort courses and events.\nThrought this I will be a student under Yee Whye Teh, co-supervised by Max Welling. I\u0026rsquo;m massivly looking forawrd to working with them on a range of exciting topics, kicking things off with a project on Distributed Bayesian Learning!\n","date":1570320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570320000,"objectID":"9a65c3fdd7d03bdd71a4eaa6ca484293","permalink":"https://mjhutchinson.github.io/news/statml_2019_begin/","publishdate":"2019-10-06T00:00:00Z","relpermalink":"/news/statml_2019_begin/","section":"news","summary":"Today marks my first day at the University of Oxford, starting a PhD in statistical Machine Learning ...","tags":null,"title":"Started at the University of Oxford","type":"news"},{"authors":["Mrinank Sharma*","**Michael Hutchinson***","Siddharth Swaroop","Antti Honkela","Richard E Turner"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"2253d7e3c06b9872d020f52d6cda862f","permalink":"https://mjhutchinson.github.io/publication/sharma-2019/","publishdate":"2019-10-01T11:50:37.61972Z","relpermalink":"/publication/sharma-2019/","section":"publication","summary":"In many real-world applications of machine learning, data are distributed across many clients and cannot leave the devices they are stored on. Furthermore, each client's data, computational resources and communication constraints may be very different. This setting is known as federated learning, in which privacy is a key concern. Differential privacy is commonly used to provide mathematical privacy guarantees. This work, to the best of our knowledge, is the first to consider federated, differentially private, Bayesian learning. We build on Partitioned Variational Inference (PVI) which was recently developed to support approximate Bayesian inference in the federated setting. We modify the client-side optimisation of PVI to provide an ($\\epsilon$, $\\delta$)-DP guarantee. We show that it is possible to learn moderately private logistic regression models in the federated setting that achieve similar performance to models trained non-privately on centralised data.","tags":null,"title":"Differentially Private Federated Variational Inference","type":"publication"},{"authors":null,"categories":null,"content":"Our paper Differnetial Private Federated Variational Inference has been accepted at the Neurips Privacy in Machine Learning workshop in Vancouver. Come say hello at the poster session if you\u0026rsquo;d like to discuss it!\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"34266be2e311c3cd9f94b132ffdd83d1","permalink":"https://mjhutchinson.github.io/news/neurips_2019_diff_priv/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/news/neurips_2019_diff_priv/","section":"news","summary":"Our paper *Differnetial Private Federated Variational Inference* has been accepted at the Neurips Privacy in Machine Learning workshop in Vancouver. Come say hello at the poster session if you'd like to discuss it!","tags":null,"title":"First paper accepted at NeurIPS Privacy in Machine Learning Workshop!","type":"news"},{"authors":["Michael Hutchinson"],"categories":[],"content":" Modern machine learning techniques are quickly being applied to a vast range of problems in the real world. However, most modern techniques are not well suited to handle a number of difficult situations. A recent piece of work we did aims to combine approaches for tackling three of these.\nSituations where we would like uncertainty estimates in our predictions For tasks such as classifying each photo in you photo library into a number of categories, or tagging them each as a particular person, the downsides to getting the decision wrong are minimal, if annoying for the end user. There are many other settings where the downsides to making the incorrect choice could mean life or death, such as medical applications, or driverless cars.\nIn these situations, we would like to know exactly how confident our model is in its predictions or decisions, so that downstream systems can account for this when taking action. For example when a driverless car is planning how to turn right, we\u0026rsquo;d very much like to know if it\u0026rsquo;s 99% sure that nothing is in its way, or if its a 50\u0026frasl;50 toss up between that and a small child.\nThis kind of problem can be solved with a more principled application of statistics to Machine Learning. When applied to deep learning this is often refereed to as Bayesian Deep Learning.\nThere exists a large body of literature in this area. In this project we focused on Variational Inference (VI) techniques.1\nSituations where the data we wish to learn from isn\u0026rsquo;t in one place It is easy to imagine that for a number of reasons, the data we want our model to learn from cannot be bought to a single locations. Examples may include legal reasons (e.g. the recent GDPR in Europe), or practical reasons (such as mobile phone/edge device data, or data that is too large to be efficiently transported).\nIn these situations, we would still like to be able to learn from this data, but many techniques cannot naively handle this. This area of work again has a large body of work, and is know as Distributed or Federated Learning.\nSituations where the data we are handling is privacy-sensitive Much of the data that we would like to use to train Machine Learning models is sensitive to someone in some way. This could be medical data, browsing history, or financial data. Data sources (i.e. the individuals from whom this data is collected) are rightly skeptical about handing over their information to third parities.\nRecent work showed that deep learning models have a tendency to memorise their input data, and using targeted attacks some input data can be recovered from them.2 In this case, the threat to a users sensitive data comes not just from people to whom they hand their data, but from anyone who has access to the models trained on their data.\nDifferential Privacy3 is the current gold standard in protecting the privacy of data while extracting information from it. By carefully processing updates, and in particular by adding noise, we can achieve a series of guarantees regarding information leakage, user utility loss, and more.\nDiffernetial Private Federated Variational Inference Our recent work builds on the Partition Variational Inference4 framework, a Variational Inference framework that allows for easy distributed and continual learning, and extends this to include privacy preserving updates based on recent differential privacy literature. There will be an arxiv preprint available soon. In the meantime, check out the code, and feel free to get in touch with any questions!\nUPDATE: This paper has been accepted to the Privacy in Machine Learning workshop at Neurips 2019!\n Blei, David M., Alp Kucukelbir, and Jon D. McAuliffe. \u0026ldquo;Variational inference: A review for statisticians.\u0026rdquo; Journal of the American statistical Association 112.518 (2017): 859-877. arxiv ^ Carlini, Nicholas, et al. \u0026ldquo;The secret sharer: Measuring unintended neural network memorization \u0026amp; extracting secrets.\u0026rdquo; arXiv preprint arXiv:1802.08232 (2018). arxiv ^ Dwork, Cynthia, and Aaron Roth. \u0026ldquo;The algorithmic foundations of differential privacy.\u0026rdquo; Foundations and Trends® in Theoretical Computer Science 9.3–4 (2014): 211-407. website ^ Bui, Thang D., et al. \u0026ldquo;Partitioned Variational Inference: A unified framework encompassing federated and continual learning.\u0026rdquo; arXiv preprint arXiv:1811.11206 (2018). arxiv ^   ","date":1569628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569628800,"objectID":"48f8c6440a6f379b0ee3a60278184382","permalink":"https://mjhutchinson.github.io/post/2019-10-01-differentially-private-pvi/","publishdate":"2019-09-28T00:00:00Z","relpermalink":"/post/2019-10-01-differentially-private-pvi/","section":"post","summary":"Learning Private, Bayesian Machine Learning Models in the Federating Learning Context","tags":[],"title":"Differential Privacy, Approximate Bayesian Inference and Distributed Learning","type":"post"}]